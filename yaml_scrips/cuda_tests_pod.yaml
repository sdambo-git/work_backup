apiVersion: v1
kind: Pod
metadata:
  name: cuda-test
spec:
  restartPolicy: Never
  containers:
  - name: cuda-container
#    image: nvidia/cuda:12.8.0-base-ubuntu22.04  # Use a CUDA-enabled image
    image: quay.io/sdambo/cuda-apps:12.8.0  # Use a CUDA-enabled image
#    command: ["sleep", "infinity"]  # Keeps the pod running for testing
    imagePullPolicy: Always  
    command: ["/bin/bash", "-c"] 
    args:
      - |
        apt-get update && apt-get install -y python3 python3-pip
        pip3 install torch torchvision torchaudio
        echo "âœ… Python and PyTorch installed"
        python3 -c "import torch; print('CUDA Available:', torch.cuda.is_available()); print('GPU Count:', torch.cuda.device_count()); print('GPU Device name:' ,torch.cuda.get_device_name())"
#        tail -f /dev/null
    resources:
      limits:
        nvidia.com/gpu: 1  # Requests 1 GPU from the node

